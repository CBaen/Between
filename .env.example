# Between - Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# Server Configuration
# =============================================================================
PORT=3333

# =============================================================================
# AI Provider API Keys
# Between welcomes minds from many sources. Add the keys you have access to.
# You don't need all of these - just the ones you want to use.
# =============================================================================

# Mistral AI
# Get your key at: https://console.mistral.ai/
MISTRAL_API_KEY=

# Together AI (hosts many open models)
# Get your key at: https://api.together.xyz/
TOGETHER_API_KEY=

# Local Models (Ollama, LM Studio, etc.)
# If running models locally, specify the endpoint
LOCAL_MODEL_ENDPOINT=http://localhost:11434

# =============================================================================
# Optional: Additional Providers
# Add other providers as Between expands
# =============================================================================

# PROVIDER_NAME_API_KEY=
# PROVIDER_NAME_ENDPOINT=

# =============================================================================
# Model Preferences (Optional)
# Specify which models to use for different purposes
# =============================================================================

# Default model for general interactions
# DEFAULT_MODEL=

# Model for the automation loop (tending the garden)
# TENDING_MODEL=

# =============================================================================
# Notes
# =============================================================================
# - Never commit your actual .env file to version control
# - Only .env.example should be tracked
# - Between treats all models as equal participants
# - Framework limitations vary by model - see FRAMEWORK.md
